{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d7046e ANN course project , Group 6\n",
    "\n",
    "The project goal is to implement a classifier for clear/cloudy sky based satellite image data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download and some checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads and extract the data from, https://drive.google.com/drive/folders/1lRCIcQo9CqFRDhUd3aZRAA46k8nLL49J\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "CLOUD_FILE_ID = \"19MBh9JIJTxYIPAeO7G5RML5_ddjJ1Cpa\"\n",
    "CLOUD_DOWN_ENDPOINT = \"https://drive.google.com/uc?id=\"\n",
    "\n",
    "base_dir = os.path.abspath(\"../data/\")  \n",
    "zip_path = os.path.join(base_dir, \"data.zip\")  \n",
    "extract_path = os.path.join(base_dir) # set to same not to create to many sub folders \n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "print(f\"downloading dataset to: {zip_path}\")\n",
    "gdown.download(f\"{CLOUD_DOWN_ENDPOINT}{CLOUD_FILE_ID}\", zip_path, quiet=False)\n",
    "\n",
    "print(f\"extracting to: {extract_path}\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "os.remove(zip_path)\n",
    "print(f\"deleted zip file: {zip_path}\")\n",
    "\n",
    "print(\"download and extraction completed.\")\n",
    "print(f\"extracted files in: {extract_path}\")\n",
    "print(f\"extracted content: {os.listdir(extract_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to figure out how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# length of gts files, trying to find out what to use and make sure where tha labels are.\n",
    "train_gts = np.load(\"../data/skogsstyrelsen-data/skogs_gts_train.npy\")\n",
    "train_names = np.load(\"../data/skogsstyrelsen-data/skogs_names_train.npy\")\n",
    "print(f\"length of train_gts:{len(train_gts)} , length of train_names:{len(train_names)}\")\n",
    "\n",
    "val_gts = np.load(\"../data/skogsstyrelsen-data/skogs_gts_val.npy\")\n",
    "val_names = np.load(\"../data/skogsstyrelsen-data/skogs_names_val.npy\")\n",
    "print(f\"length of train_gts:{len(val_gts)} , length of train_names:{len(val_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample on of the objects in the .nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a .nc array \n",
    "import xarray as xar\n",
    "ds = xar.open_dataset(\"../data/skogsstyrelsen-data/2A-netcdfs-cropped-from-nuria/skgs_0b5101fb-44c7-ed11-9174-005056a6f472.nc\") # first file from the download folder\n",
    "print(ds)\n",
    "\n",
    "scl_value = ds['scl'].values\n",
    "print(f\"\\nscl_value:\\n{scl_value}\")\n",
    "\n",
    "bands = []\n",
    "\n",
    "# print some of the object attributes, familiarize with the structure of the data\n",
    "for band in ds.data_vars:\n",
    "    data_array = ds[band]\n",
    "    values = data_array.values\n",
    "    bands.append(values)\n",
    "\n",
    "    print(f\"Variable name: {band}\")\n",
    "    print(f\"Shape: {values.shape}\")\n",
    "    print(f\"Dtype: {values.dtype}\\n\")\n",
    "\n",
    "print(f\"bands array:\\n{bands}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup Cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xar\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DATA_PATH = \"../data/skogsstyrelsen-data/\"\n",
    "BANDS = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b08', 'b8a', 'b09', 'b11', 'b12']\n",
    "IMAGE_SIZE = 20 # bands array from the above print seems to have shape 20X20, 2D \n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\n",
    "        \"Cuda does not seem to be available in your environment, try installing a torch package compiled with cuda enabled if u have cuda installed in ur os.\\n\"\n",
    "        \"Uninstall torch, torchaudio, torchvision, and then run: torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\\n\"\n",
    "    )\n",
    "    \n",
    "print(f\"Running with: DEVICE = {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utils functions to load the data from skogs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_skogs_paths(split_suffix: str):\n",
    "    \"\"\" Returns concatenated paths depending on what split that is needed. \"\"\"\n",
    "    names_path = os.path.join(DATA_PATH, f\"skogs_names_{split_suffix}.npy\")\n",
    "    labels_path = os.path.join(os.path.join(DATA_PATH, f\"skogs_gts_{split_suffix}.npy\"))\n",
    "    return names_path, labels_path\n",
    "\n",
    "def load_skogs_data(split_suffix: str):\n",
    "    \"\"\"Loads a dataset split into numpy arrays for images and binary labels.\"\"\"\n",
    "    names_path, labels_path = get_skogs_paths(split_suffix)\n",
    "    names = np.load(names_path, allow_pickle=True)  # list of paths to nc files\n",
    "    labels = np.load(labels_path, allow_pickle=True).astype(np.float32)  # binary values from the gts files\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for name, label in zip(names, labels):  \n",
    "        nc_file = os.path.join(DATA_PATH, \"2A-netcdfs-cropped-from-nuria\", os.path.basename(name)) # could not get the path to work with just the path from names file\n",
    "        nc_file = os.path.normpath(nc_file)  # normalize path for different OS\n",
    "\n",
    "        if os.path.exists(nc_file):\n",
    "            with xar.open_dataset(nc_file, engine=\"netcdf4\") as ds:\n",
    "                band_arrays = [(ds[band].values.squeeze() - 1000) / 10000 for band in BANDS]\n",
    "\n",
    "            # reshape bands of different shapes \n",
    "            band_arrays_fixed = []\n",
    "            for band in band_arrays:\n",
    "                if band.shape[0] >= IMAGE_SIZE and band.shape[1] >= IMAGE_SIZE:\n",
    "                    band_fixed = torch.tensor(band[:IMAGE_SIZE, :IMAGE_SIZE], dtype=torch.float32) # slice the top left part of the image consistently, \n",
    "                else:                                                                              # mby need to change the slice if important features are lost\n",
    "                    band_fixed = torch.zeros((IMAGE_SIZE, IMAGE_SIZE), dtype=torch.float32)\n",
    "                \n",
    "                band_arrays_fixed.append(band_fixed)\n",
    "\n",
    "                x = torch.stack(band_arrays_fixed)  # should be of size (batch_size, 20, 20) when stacking\n",
    "        else:\n",
    "            print(f\"File not found: {nc_file}\")\n",
    "            x = torch.zeros((len(BANDS), IMAGE_SIZE, IMAGE_SIZE), dtype=torch.float32) \n",
    "\n",
    "        x_list.append(x.numpy())  \n",
    "        y_list.append(label)  \n",
    "\n",
    "    return np.array(x_list), np.array(y_list)  \n",
    "\n",
    "class SkogsBinaryDataset(Dataset):\n",
    "    \"\"\" PyTorch dataset for the stacked band arrays (X) and binary label (y). \"\"\"\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data # tensor for the image\n",
    "        self.y_data = y_data # label for the image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.x_data[idx], dtype=torch.float32)  # shape: (bands, rows, cols), (12, 21, 20)\n",
    "        y = torch.tensor(self.y_data[idx], dtype=torch.float32)  # shape: (72), just the labels from the gts file\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up data loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch_shapes(ds: DataLoader):\n",
    "    for x_batch, y_batch in ds:\n",
    "        print(f\"x_batch shape: {x_batch.shape}\") # (batch_size, channels, height, width)\n",
    "        print(f\"y_batch shape: {y_batch.shape}\") # (batch_size) , same amount of labels as input images\n",
    "\n",
    "x_train, y_train = load_skogs_data(\"train\")\n",
    "x_val, y_val = load_skogs_data(\"val\")\n",
    "x_test, y_test = load_skogs_data(\"test\")\n",
    "\n",
    "train_ds = SkogsBinaryDataset(x_train, y_train)\n",
    "val_ds = SkogsBinaryDataset(x_val, y_val)\n",
    "test_ds = SkogsBinaryDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) \n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# uncomment if u want to check shapes\n",
    "#check_batch_shapes(train_loader)\n",
    "check_batch_shapes(val_loader)\n",
    "#check_batch_shapes(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model architecture 1**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
